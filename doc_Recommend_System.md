# ì¶”ì²œ ì‹œìŠ¤í…œ

ë¶„ì•¼ì— ë”°ë¥¸ ë…¼ë¬¸ ì¶”ì²œì˜ ê²½ìš° ì´ 43ê°œì˜ ë¶„ì•¼ê°€ ìˆì–´ 2ê°œ ì´ìƒì˜ ë ˆì´ë¸”ì„ ê°€ì§€ê³  ìˆìœ¼ë¯€ë¡œ **ë‹¤ì¤‘ ë¶„ë¥˜ (Multiclass classification)** ì˜ ì˜ˆì…ë‹ˆë‹¤. ê° ë°ì´í„°ì˜ í¬ì¸í„°ê°€ ì •í™•íˆ í•˜ë‚˜ì˜ ë²”ì£¼ë¡œ ë¶„ë¥˜ë˜ê¸° ë•Œë¬¸ì— **ë‹¨ì¼ ë ˆì´ë¸” ë‹¤ì¤‘ ë¶„ë¥˜ (single-label, multiclass classification)** ë¬¸ì œì…ë‹ˆë‹¤.



## ğŸ“Œ ëª©ì°¨

* [ì‹œì‘í•˜ê¸°](#-ì‹œì‘í•˜ê¸°)

  * [ì¤€ë¹„í•˜ê¸°](#ì¤€ë¹„í•˜ê¸°)

* [ì›Œí¬í”Œë¡œìš°](#-ì›Œí¬í”Œë¡œìš°)

* [ë…¼ë¬¸ ë°ì´í„°](#-ë…¼ë¬¸-ë°ì´í„°)

* [ë°ì´í„° ì •ì œ](#-ë°ì´í„°-ì •ì œ)

  * [í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬](#í…ìŠ¤íŠ¸-ì „ì²˜ë¦¬)
    * [ì •ì œ (Cleaning) & ì •ê·œí™” (Normalization) & í† í°í™” (Tokenization)](#ì •ì œ-(Cleaning)-&-ì •ê·œí™”-(Normalization)-&-í† í°í™”-(Tokenization))
  * [ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬](#ëª¨ë¸ë§ì„-ìœ„í•œ-ë°ì´í„°-ì „ì²˜ë¦¬)
    * [ë°ì´í„° êµ¬ë¶„](#ë°ì´í„°-êµ¬ë¶„)
    * [ë°ì´í„° ë³€í™˜](#ë°ì´í„°-ë³€í™˜)

* [ë¶„ë¥˜ ëª¨ë¸ ìƒì„±](#-ë¶„ë¥˜-ëª¨ë¸-ìƒì„±)

* [ë¶„ë¥˜ ëª¨ë¸ í‰ê°€](#-ë¶„ë¥˜-ëª¨ë¸-í‰ê°€)

* [ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜](#-ì¶”ì²œ-ì•Œê³ ë¦¬ì¦˜)

  * [ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§](#-ì½˜í…ì¸ -ê¸°ë°˜-í•„í„°ë§)
  * [ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§](#ì•„ì´í…œ-ê¸°ë°˜-í˜‘ì—…-í•„í„°ë§)
    * [ë°ì´í„°](#ë°ì´í„°)
  * [ì ì¬ ìš”ì¸ í˜‘ì—… í•„í„°ë§](ì ì¬-ìš”ì¸-í˜‘ì—…-í•„í„°ë§)
    * [ë°ì´í„°](ë°ì´í„°)

* [ì°¸ê³ ](#ì°¸ê³ )

  

## :runner: ì‹œì‘í•˜ê¸°

### ì¤€ë¹„í•˜ê¸°

í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:

```shell
$ pip install -r requirements.txt
```

```
# requirements.txt
numpy==1.19.1
pandas==1.1.1
tensorflow==2.0.0
keras==2.3.1
matplotlib==3.3.1
nltk==3.5
scikit-learn==0.23.2
pandas-profiling==2.9.0
```

## ğŸ’» ì›Œí¬í”Œë¡œìš°

ì•„ë˜ì™€ ê°™ì€ ì›Œí¬í”Œë¡œìš°ë¡œ ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ì˜€ìŠµë‹ˆë‹¤.

1. **ìˆ˜ì§‘(Acquisition)**: í¬ë¡¤ë§ ë° OpenAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ë…¼ë¬¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
2. **ì ê²€ ë° íƒìƒ‰(Inspection and exploration)**: íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(Exploratory Data Analysis, EDA)ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì •ì œí•´ì•¼í•˜ëŠ”ì§€ íŒŒì•…í•©ë‹ˆë‹¤.
3. **ì „ì²˜ë¦¬ ë° ì •ì œ(Processing and Cleaning)**: í† í°í™”, ì •ì œ, ì •ê·œí™”, ë¶ˆìš©ì–´ ì œê±° ë“±ì˜ ë‹¨ê³„ë¥¼ í†µí•´ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
4. **ëª¨ë¸ë§ ë° í›ˆë ¨(Modeling and Training)**: ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„°ë¥¼ í†µí•´ ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤. ì´ ë•Œ, ì „ì²´ë°ì´í„° ì¤‘ 8:2ì˜ ë¹„ìœ¨ë¡œ í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤. ë˜í•œ, í›ˆë ¨ ë°ì´í„° ì¤‘ 8:2ì˜ ë¹„ìœ¨ë¡œ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤. (Training : Validation : Testing = 6.4 : 1.6 : 2.0)
5. **í‰ê°€(Evaluation)**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
6. **ë°°í¬(Deployment)**: ì™„ì„±ëœ ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤.

## :page_with_curl: ë…¼ë¬¸ ë°ì´í„°

ë…¼ë¬¸ ë°ì´í„°ëŠ” **KCI** (https://www.kci.go.kr/kciportal/main.kci) í™ˆí˜ì´ì§€ì—ì„œ í¬ë¡¤ë§ ë° OpenAPIë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ê² ìŠµë‹ˆë‹¤. ì´ 43ê°œì˜ ë¶„ë¥˜ë¡œ ë‚˜ë‰˜ë©° ì–´ë–¤ ë¶„ë¥˜ëŠ” ë‹¤ë¥¸ ê²ƒì— ë¹„í•´ ë°ì´í„°ê°€ ë§ìŠµë‹ˆë‹¤. ê° ë¶„ë¥˜ëŠ” í›ˆë ¨ ì„¸íŠ¸ì— í‰ê· 23ê°œ ì´ìƒì˜ ìƒ˜í”Œì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

![image-20200929021753979](C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\image-20200929021753979.png)



## :gear: ë°ì´í„° ì •ì œ

### í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬

#### ì •ì œ (Cleaning) & ì •ê·œí™” (Normalization) & í† í°í™” (Tokenization)

ì •ì œë€ ê°€ì§€ê³  ìˆëŠ” í…ìŠ¤íŠ¸ë¡œë¶€í„° ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” ì—­í• ì„ í•˜ë©°, ì •ê·œí™”ëŠ” í‘œí˜„ ë°©ë²•ì´ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ í†µí•©ì‹œì¼œ ê°™ì€ ë‹¨ì–´ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤. ì£¼ì–´ì§„ ë§ë­‰ì¹˜ì— ëŒ€í•´ í† í°ì´ë¼ ë¶ˆë¦¬ëŠ” ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ í† í°í™”ë¼ ì–˜ê¸°í•˜ë©°, í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì—ì„œëŠ” í† í°ì˜ ë‹¨ìœ„ë¥¼ ë‹¨ì–´ë¡œ ë§Œë“¤ê¸° ìœ„í•´ ë‹¨ì–´ í† í°í™”(word tokenization)ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ë°ì´í„°ì— ì •ì œì™€ ì •ê·œí™” ë° í† í°í™”ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.

1. abstractì˜ íŠ¹ìˆ˜ë¬¸ì, ê¸¸ì´ê°€ ì§§ì€ ë‹¨ì–´ë¥¼ ì œê±°í•˜ê³  ì†Œë¬¸ìë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

   ```python
   df["abstract_clean"] = df["abstract"].str.replace("[^a-zA-Z]", " ")
   df["abstract_clean"] = df["abstract_clean"].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))
   df["abstract_clean"] = df["abstract_clean"].apply(lambda x: x.lower())
   ```

2. nullê°’ ë° emptyê°’ì„ í™•ì¸í•´ ì œê±°í•©ë‹ˆë‹¤.

   ```python
   # Null ê°’ ë° emptyê°’ í™•ì¸
   df["abstract_clean"].isnull().values.any()
   df.replace("", float("NaN"), inplace=True)
   df["abstract_clean"].isnull().values.any()
   df.dropna(inplace=True)
   ```

3. labelì´ ì—†ëŠ” ê°’ì„ í™•ì¸í•´ ì œê±°í•©ë‹ˆë‹¤.

   ```python
   df = df[df.label != 0]
   ```

4. nltk ìì—°ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•˜ì—¬ 'is', 'the', 'a'ì™€ ê°™ì€ ë¶ˆìš©ì–´(stopwords)ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.

   ```python
   from nltk.corpus import stopwords
   # ë¶ˆìš©ì–´ ì œê±°
   stop_words = stopwords.words('english')
   tokenized_doc = df['abstract_clean'].apply(lambda x: x.split())
   tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])
   tokenized_doc = tokenized_doc.to_list()
   ```

5. ë‹¨ì–´ê°€ 1ê°œ ì´í•˜ì¸ ìƒ˜í”Œì˜ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ì„œ ì €ì¥í•˜ê³ , í•´ë‹¹ ìƒ˜í”Œë“¤ì€ ì œê±°í•©ë‹ˆë‹¤.

   ```python
   drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]
   tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)
   df['tokenized_doc'] = tokenized_doc
   ```

### ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ì „ì²˜ë¦¬

#### ë°ì´í„° êµ¬ë¶„

ëª¨ë¸ì˜ í•™ìŠµì„ ìœ„í•´ í›ˆë ¨ ë°ì´í„°, ê²€ì¦ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ êµ¬ë¶„í•©ë‹ˆë‹¤. ëœë¤í•˜ê²Œ ì„ì€ ì „ì²´ë°ì´í„° ì¤‘ 8:2ì˜ ë¹„ìœ¨ë¡œ í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤. ë˜í•œ, í›ˆë ¨ ë°ì´í„° ì¤‘ 8:2ì˜ ë¹„ìœ¨ë¡œ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ë¥¼ ë‚˜ëˆ´ìŠµë‹ˆë‹¤. (Training : Validation : Testing = 6.4 : 1.6 : 2.0)

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df['tokenized_doc'], df['label'], test_size= 0.2, random_state=1234)
# X_train, y_train: í›ˆë ¨ ë°ì´í„°, í›ˆë ¨ ë°ì´í„° ì •ë‹µ
# X_test, y_test: í…ŒìŠ¤íŠ¸ ë°ì´í„°, í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë‹µ
```

#### ë°ì´í„° ë³€í™˜

ì •ì œ, ì •ê·œí™”, í† í°í™”ë¥¼ í†µí•´ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ëª¨ë¸ë§ì„ ìœ„í•´ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ë ˆì´ë¸”ì„ ë²¡í„°ë¡œ ë°”ê¾¸ê¸° ìœ„í•´ì„œ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ìˆ˜ í…ì„œë¡œ ë³€í™˜í•˜ëŠ” ì›-í•« ì¸ì½”ë”©(one-hot encoding)ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ ë•Œ,  ì •ìˆ˜í™”ëœ ë°ì´í„° ì¤‘ ê°€ì¥ ê¸´ ê¸¸ì´ì¸ 398ì— ë§ì¶° ì •ê·œí™” ë° ë²¡í„°í™”ì‹œí‚µë‹ˆë‹¤.

![image-20200929030524195](C:\Users\multicampus\AppData\Roaming\Typora\typora-user-images\image-20200929030524195.png)

```python
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical
import numpy as np

# ë¬¸ìì—´ì„ ì •ìˆ˜ ì¸ë±ìŠ¤ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
tokenizer = Tokenizer(num_words=35000)
tokenizer.fit_on_texts(X_train)
X_train = tokenizer.texts_to_sequences(X_train)
X_test = tokenizer.texts_to_sequences(X_test)

# ë°ì´í„° ì •ê·œí™”
X_train = pad_sequences(X_train,maxlen=350)
X_test = pad_sequences(X_test,maxlen=350)
y_train = to_categorical(np.asarray(y_train))
y_test = to_categorical(np.asarray(y_test))

# ë°ì´í„° ë²¡í„° ë³€í™˜
def vectorize_sequences(sequences, dimension=35000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.
    return results

X_train = vectorize_sequences(X_train) # í›ˆë ¨ ë°ì´í„° ë²¡í„° ë³€í™˜
X_test = vectorize_sequences(X_test) # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë²¡í„° ë³€í™˜
```

> **Tip**
>
> One-Hot Encoding?
>
> ë¬¸ìë¥¼ ìˆ«ìë¡œ ë°”ê¾¸ëŠ” ì—¬ëŸ¬ê°€ì§€ ê¸°ë²• ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤. ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ë‹¨ì–´ë“¤ì„ ê°€ì§„ ë‹¨ì–´ ì§‘í•©(vocabulary)ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ê°€ì§€ê³  ë¬¸ìë¥¼ ìˆ«ì(ì¦‰, ë²¡í„°)ë¡œ ë°”ê¿‰ë‹ˆë‹¤.
>
> (1) ê° ë‹¨ì–´ì— ê³ ìœ í•œ ì¸ë±ìŠ¤ë¥¼ ë¶€ì—¬í•©ë‹ˆë‹¤. (ì •ìˆ˜ ì¸ì½”ë”©)
> (2) í‘œí˜„í•˜ê³  ì‹¶ì€ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ì˜ ìœ„ì¹˜(class)ì— 1ì„ ë¶€ì—¬í•˜ê³ , ë‹¤ë¥¸ ë‹¨ì–´ì˜ ì¸ë±ìŠ¤ì˜ ìœ„ì¹˜(class)ì—ëŠ” 0ì„ ë¶€ì—¬í•©ë‹ˆë‹¤.

## :book: ë¶„ë¥˜ ëª¨ë¸ ìƒì„±

í•™ìŠµì„ ìœ„í•´ relu í™œì„±í™” í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ ì™„ì „ ì—°ê²° ì¸µì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. loss í•¨ìˆ˜ëŠ” categorical_crossentropyë¥¼ ì‚¬ìš©í•˜ì˜€ê³  rmsprop ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

* ì´ 4ê°œì˜ Dense ì¸µì„ ì‚¬ìš©í•´ ê° ì¸µë§ˆë‹¤ ì°¨ë¡€ëŒ€ë¡œ 512, 256, 128ê°œì˜ ì€ë‹‰ ìœ ë‹›(hidden unit)ì„ ì‚¬ìš©í–ˆê³ , reluí™œì„±í™” í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë‹¤ìŒ í…ì„œ ì—°ì‚°ì„ ì—°ê²°í–ˆìŠµë‹ˆë‹¤. 
* ë§ˆì§€ë§‰ ì¸µì˜ 44ê°œëŠ” 44ì°¨ì›(43ê°œì˜ ë¶„ë¥˜ + 0ê°’ì„ ê°€ì§„ label) ì˜ ë²¡í„°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. 
* ë§ˆì§€ë§‰ ì¸µì— softmax í™œì„±í™” í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì–´ 44ê°œì˜ ì¶œë ¥ í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ì¦‰, 44ê°œì˜ ì¶œë ¥ ë²¡í„°ë¥¼ ë§Œë“¤ë©° output[i]ëŠ” ì–´ë–¤ ìƒ˜í”Œì´ í´ë˜ìŠ¤ iì— ì†í•  í™•ë¥ ë¡œ ëª¨ë‘ ë”í•˜ë©´ 1ì´ë©ë‹ˆë‹¤.

```python
from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout, MaxPooling1D
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(35000,)))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(44, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(X_train, y_train, epochs = 30, batch_size=50, validation_split=0.2)
```

## :chart_with_upwards_trend: ë¶„ë¥˜ ëª¨ë¸ í‰ê°€

```python
results = model.evaluate(X_test, y_test)
```

## :link: ì¶”ì²œ ì•Œê³ ë¦¬ì¦˜

### ì»¨í…ì¸  ê¸°ë°˜ í•„í„°ë§

ì¶”ì²œ ì‹œìŠ¤í…œ ì¤‘ ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ (Content Based Filtering)ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§ì˜ ê²½ìš°, ì‚¬ìš©ìê°€ íŠ¹ì • ì•„ì´í…œì„ ì„ í˜¸í•˜ëŠ” ê²½ìš° ê·¸ ì•„ì´í…œê³¼ ë¹„ìŠ·í•œ ì½˜í…ì¸ ë¥¼ ê°€ì§„ ë‹¤ë¥¸ ì•„ì´í…œì„ ì¶”ì²œí•´ì¤ë‹ˆë‹¤. ã…‡ã…‡ì‹œìŠ¤í…œì—ì„œëŠ” íšŒì›ê°€ì… ì‹œ ì„ í˜¸í•˜ëŠ” ë¶„ë¥˜ 3ê°œë¥¼ ì„ íƒí•´ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì‚¬ìš©ìê°€ ìš”ì•½ì„ ìœ„í•´ ì—…ë¡œë“œí•œ ë…¼ë¬¸ì„ ì•ì„œ í•™ìŠµì‹œí‚¨ ë¶„ë¥˜ê¸° ëª¨ë¸ì„ í†µí•´ ë¶„ì•¼ë¥¼ íŒŒì•…í•˜ê³  í•´ë‹¹ ë¶„ì•¼ì—ì„œ ë‚´ìš©ì´ ë¹„ìŠ·í•œ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì¤ë‹ˆë‹¤.

1. ìš”ì•½ëœ ë…¼ë¬¸ì˜ abstractë¥¼ ë¶„ë¥˜ê¸°ë¥¼ í†µí•´ ë¶„ì•¼ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
2. í•´ë‹¹ ë¶„ì•¼ì—ì„œ keyword, title, scrap, quoteë¥¼ ì „ì²˜ë¦¬ë¥¼ í†µí•´ ìŠ¤í¬ë©ìˆ˜ì™€ ì¸ìš©ìˆ˜ê°€ ë§ì€ ë…¼ë¬¸ì¼ìˆ˜ë¡ ë” ë†’ì€ ì ìˆ˜ë¥¼ ì¤ë‹ˆë‹¤. 
3. ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ë…¼ë¬¸ 500ê°œ ì¤‘, 'keyword'ì™€ 'title'ì˜ ë‚´ìš©ì´ ë¹„ìŠ·í•œ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì¤ë‹ˆë‹¤. ì´ ë•Œ, ì½”ì‚¬ì¸ ìœ ì‚¬ë„(cosine similarity)ê°€ ë†’ì€ ë…¼ë¬¸ì„ ì¶”ì²œí•´ì£¼ê²Œ ë©ë‹ˆë‹¤.

### ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§

ìµœê·¼ì ‘ ì´ì›ƒ ê¸°ë°˜(nearest neighbor based collaborative filtering) í˜‘ì—…í•„í„°ë§ì€ ì‚¬ìš©ì ê¸°ë°˜ì˜ í˜‘ì—… í•„í„°ë§(user based collaborative filtering)ê³¼ ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§(item based collaborative filtering)ìœ¼ë¡œ ë‚˜ë‰˜ì–´ì§‘ë‹ˆë‹¤.

ì €í¬ê°€ ì‚¬ìš©í•œ ì•„ì´í…œ ê¸°ë°˜ í˜‘ì—… í•„í„°ë§ì˜ ê²½ìš°, item-user í–‰ë ¬ ë‚´ì—ì„œ itemAê³¼ itemBê°€ ìœ ì‚¬í•œ í‰ì  ë¶„í¬ë¥¼ ê°€ì§€ê³  ìˆë‹¤ë©´ itemAì™€ itemBê°€ ìœ ì‚¬í•˜ë‹¤ê³  íŒë‹¨í•©ë‹ˆë‹¤.

#### ë°ì´í„°

ë°ì´í„°ì—ëŠ” ì‚¬ìš©ìê°€ ìŠ¤í¬ë©í•œ ë…¼ë¬¸ ë°ì´í„° (reports_scraps í…Œì´ë¸”)ì™€ ë…¼ë¬¸ ë°ì´í„° (all_data.pkl)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

### ì ì¬ ìš”ì¸ í˜‘ì—… í•„í„°ë§

ì ì¬ ìš”ì¸ í˜‘ì—… í•„í„°ë§(latent factor collaborative filtering)ì€ í–‰ë ¬ ë¶„í•´(matrix factorization)ì„ ê¸°ë°˜í•´ ì‚¬ìš©í•©ë‹ˆë‹¤. ë‹¤ì°¨ì› í–‰ë ¬ì„ SVDì™€ ê°™ì€ ì°¨ì› ê°ì†Œ ê¸°ë²•ìœ¼ë¡œ ë¶„í•´í•˜ëŠ” ê³¼ì •ì—ì„œ ì ì¬ ìš”ì¸(latent factor)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ í–‰ë ¬ ë¶„í•´ë¥¼ í•˜ê²Œë˜ë©´ ê³µê°„ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ê¸°ì¡´ì˜ item-user í–‰ë ¬ì„ user-latent, item-latent í–‰ë ¬ë¡œ ë¶„í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

* item-user: *R(u, i)*

  * uë²ˆì§¸ ìœ ì €ê°€ ië²ˆì§¸ ì•„ì´í…œ í‰ê°€ ì ìˆ˜

* user-latent: *P(u, k)*

* item-latent: *Q(i, k)*

  => *R(u, i)* â‰’ *P(u, k)* * *Q.T(k, i)*

#### ë°ì´í„°

ë°ì´í„°ì—ëŠ” ì‚¬ìš©ìê°€ ìŠ¤í¬ë©í•œ ë…¼ë¬¸ ë°ì´í„° (reports_scraps í…Œì´ë¸”)ì™€ ë…¼ë¬¸ ë°ì´í„° (all_data.pkl)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

## :books: ì°¸ê³ 

* [í…ì„œ í”Œë¡œìš° ë¸”ë¡œê·¸](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/3-5-%EB%89%B4%EC%8A%A4-%EA%B8%B0%EC%82%AC-%EB%B6%84%EB%A5%98-%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98-%EB%AC%B8%EC%A0%9C/)
* [ë”¥ ëŸ¬ë‹ì„ ì´ìš©í•œ ìì—°ì–´ ì²˜ë¦¬ ì…ë¬¸](https://wikidocs.net/book/2155)
* [ê¿ˆ ë§ì€ ì‚¬ëŒì˜ ì´ì•¼ê¸°](https://lsjsj92.tistory.com/563)
* https://lsjsj92.tistory.com/571?category=853217

